# ðŸŸ¢ IndicTrans2

* <mark style="color:purple;background-color:purple;">**2023**</mark>
* <mark style="color:purple;background-color:purple;">**Supports 22 languages**</mark>
* <mark style="color:purple;background-color:purple;">**Trained on Bharat Parallel Corpus Collection (BPCC) approximately 230 million bitext pairs**</mark>
* The model is trained in a many-to-many setup, supporting translation between multiple Indian languages without always using English as a pivot.
* <mark style="color:purple;background-color:purple;">**It comes in multiple sizes, including a distilled 320M parameter version and larger high-capacity versions (\~1B+).**</mark>
*

    <figure><img src="../.gitbook/assets/image (1).png" alt=""><figcaption></figcaption></figure>
