# IndicTrans2

* &#x20;Supports 22 languages
* Trained on Bharat Parallel Corpus Collection (BPCC) approximately 230 million bitext pairs
* The model is trained in a many-to-many setup, supporting translation between multiple Indian languages without always using English as a pivot.
* It comes in multiple sizes, including a distilled 320M parameter version and larger high-capacity versions (\~1B+).
*

    <figure><img src="../.gitbook/assets/image.png" alt=""><figcaption></figcaption></figure>
