# IndicTrans Finetuning

* Organize the traning data as en-X folders where each folder has two text files containing parallel data for en-X lang pair
* Using fairseq we will finetune it&#x20;
* Uning nvidia t7 it would take about half day to train
*   **Good practical fine-tune:** **\~10k–50k** parallel pairs — _reliable domain adaptation, measurable BLEU/chrF gains, handles terminology and style._

    <figure><img src="../.gitbook/assets/{08675883-D232-47B7-B92D-39B02029A043}.png" alt=""><figcaption></figcaption></figure>
