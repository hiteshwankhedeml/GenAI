# IndicTrans

* IndicTrans uses 6 encoder and decoder layers, input embeddings of size 1536 with 16 attention heads and feedforward dimension of 4096 with total number of parameters of 434M
* Specifically built for Indian languages
* IndicTrans achieved higher BLEU scores on multiple Indic translation tasks compared to mBART, M2M-100, GNMT baselines
* Direct Indicâ†”Indic translation
* Most models required English as a pivot.
* IndicTrans supported direct translation between Indic languages, reducing error propagation.

