# Format Instructions vs Instructor API

* **LangChain + Prompt (Format Instructions / `PydanticOutputParser`)**
  * You define a `Pydantic` model.
  * `parser.get_format_instructions()` injects the schema description into the prompt.
  * The LLM _tries_ to follow it.
  * Output is parsed into the Pydantic object.
  * âŒ If the LLM returns invalid JSON â†’ parsing fails â†’ you must handle retries.
  * âœ… Good for prototypes, not 100% reliable.

***

* **Instructor API**
  * You patch the LLM (`llm = patch(ChatOpenAI(...))`).
  * Pass `response_model=YourPydanticModel` directly.
  * Instructor enforces schema, validates output, retries automatically.
  * Always returns a valid **Pydantic object**.
  * âœ… Production-grade safety.

***

#### ğŸ”‘ Key Difference

| Feature               | Format Instructions / PydanticOutputParser | Instructor API            |
| --------------------- | ------------------------------------------ | ------------------------- |
| Enforcement           | Relies on prompt, not strict               | Strict schema validation  |
| Invalid JSON Handling | Manual retries needed                      | Auto-retries & correction |
| Output                | Raw â†’ parsed                               | Direct Pydantic object    |
| Best for              | Prototypes, experiments                    | Production apps           |

***

âš¡ **Summary**:

* _Prompt-only instructions_ = â€œLLM, please follow this formatâ€ â†’ not guaranteed.
* _Instructor API_ = â€œLLM, you must return this schemaâ€ â†’ guaranteed.

